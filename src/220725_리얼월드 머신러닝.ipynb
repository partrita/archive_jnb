{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.\n",
    "\n",
    "*헨릭 브링크, 리얼월드 머신러닝, 위키북스, 2017*\n",
    "\n",
    "# 1. 머신러닝 소개\n",
    "\n",
    "- 1장 에서는 머신러닝의 소개\n",
    "- 2장 에서는 데이터 전처리 단계\n",
    "- 3장 에서는 간단한 머신러닝 모델의 구축\n",
    "- 4장 모델의 성능을 평가하고 최적화하는 방법\n",
    "- 5장 feature engineering(특성 공학)\n",
    "\n",
    "## 1.1. 머신러닝이란?\n",
    "\n",
    "전통적인 의사결정 방식과는 다르게 데이터를 바탕으로 자체적인 모델을 형상한다는 점에서 구별됩니다, 기본적인 작업흐름은 다음과 같습니다.\n",
    "1. 데이터 준비\n",
    "2. 모델 만들기\n",
    "3. 모델 평가하기\n",
    "4. 최적화 및 데이터 예측\n",
    "\n",
    "머신러닝의 학습방법은 다음과 같이 크게 두가지로 분류할 수 있습니다.\n",
    "- supervised learning : 레이블이 있는 데이터를 사용한 학습법, 대부분의 머신러닝이 해당\n",
    "     + 목표가 범주형: 분류 문제\n",
    "     + 목표가 수치형: 회귀 문제\n",
    "- unsupervied learning :  레이블이 없는 데이터에서 규칙을 찾는 학습법, 다음과 같은 두가지 접근법이 있습니다.\n",
    "    + 군집화(clustering): K-means, 계층 군집화, 가우스 혼합 모델 \n",
    "    + 차원축소: 주성분 분석, 다차원 척도법, 다면체 학습\n",
    "\n",
    "## 1.2. 데이터의 중요성\n",
    "아무리 최신의 알고리즘이어도 무엇 보다도 데이터가 성능에 가장큰 영향을 줍니다. 훈련 데이터를 수집하는 단계는 아래와 같습니다.\n",
    "1. 포함할 입력 특성 결정\n",
    "2. 목표 변수를 위한 실측 자료값을 어떻게 얻을지 결정\n",
    "3. 훈련 데이터를 모을 시기를 결정\n",
    "4. 훈련 데이터는 편향되지 않고 전체를 대표해야 합니다.\n",
    "\n",
    "훈련 데이터의 전처리 단계는 다음과 같습니다.\n",
    "1. 법주형 특성 기록\n",
    "2. 결측 자료 처리\n",
    "3. 특성의 정규화\n",
    "4. 특성 추출\n",
    "\n",
    "## 1.3. 학습 모델의 구축\n",
    "머신러닝의 주요 목표는 다음 두가지 입니다. 예측(prediction)과 추론(inference). \n",
    "\n",
    "머신러닝의 모델의 주요 형태는 두 가지 입니다. 매개변수 모델과 비매개변수 모델. 두가지의 본질 적인 차이는, 매개 변수 모델을 *f*가 특정한 함수의 형태를 가지고 있다고 가정하는 반면에, 비매개변수 모델은 그러한 가정을 하지 않는다는 점에 있습니다. 따라서 매개변수 접근법이 상대적으로 단순하지만 정확성이 낮다는 특성이 있습니다.\n",
    "### 1.3.1. 매개변수(parametric) 방식\n",
    "- 선형회귀\n",
    "- 로지스틱 회귀\n",
    "- 다항식 회쉬\n",
    "- 선형 판별 분석\n",
    "- 이차 판별 분석\n",
    "- 혼합모형\n",
    "- 나이브 베이즈\n",
    "\n",
    "매개변수 모델과 함께 모델 선택에 사용되는 접근법으로는 \n",
    "- ridge regression\n",
    "- lasso regression\n",
    "- PCA\n",
    "// 각각의 설명은 부록을 참고\n",
    "### 1.3.2. 비매개변수(nonparametric) 방식\n",
    "비매개변수 방식은 실제 데이터 분석에 많이 사용되는 방법입니다. 접근법의 예로는\n",
    "- 분류트리\n",
    "- k 최근접 이웃\n",
    "- 기저확장법\n",
    "- 신경망\n",
    "- 커널 스무딩\n",
    "- 일반화 가법 모형\n",
    "- 배깅\n",
    "- 부스팅\n",
    "- 랜덤 포레스트\n",
    "- 서포트 벡터 머신\n",
    "//부록 참조\n",
    "\n",
    "\n",
    "## 1.4. 모델 평가와 최적화\n",
    "머신러닝의 모델을 평가할때는 훈련용 데이터로 오차율을 구하면 안됩니다. 따라서 신규 데이터로 **교차 검증**(cross-validation)을 해야 합니다.\n",
    "교차검정을 위해 사용되는 두가지 방법이 있습니다.\n",
    "1. 홀드아웃 방법\n",
    "    - 훈련 데이터 중 임의의 부분을 나누어서 훈련용과 테스트용으로 따로 사용하는 방법입니다.\n",
    "2. K-fold 교차 검증\n",
    "    - 홀드 아웃보다는 탁월하지만, 계산량이 더 많은 방법입니다. 위의 방법과 유사하나, K개의 부분집합들로 데이터를 분활해서 사용한다는 것입니다.\n",
    "\n",
    "분류 모델\n",
    "- 간단한 계산 정확도\n",
    "- 혼동 행렬\n",
    "- 수신자 조작 특성\n",
    "- ROC 곡선\n",
    "\n",
    "회귀모델\n",
    "- RMSE\n",
    "- R<sup>2</sup>\n",
    "\n",
    "그리드 탐색\n",
    "## 1.5. 특성 공학 feature engineering\n",
    "입력 데이터를 수학적으로 변환해 머신러닝에 알맞는 특성으로 만드는 것입니다. 특성 추출은 모델을 만들기전에 하는 것이 좋습니다. \n",
    "\n",
    "### 1.5.1. 유용한 이유 \n",
    "1. 데이터를 변형해 목표와 관련 짓기\n",
    "2. 외부 데이터 가져오기\n",
    "3. 비정형 데이터 자료 사용\n",
    "4. 해석하기 쉬운 특성 만들기\n",
    "5. 많은 특성 집합을 사용해 창조성 향상\n",
    "\n",
    "어떻게 하는 것인가?b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C', 65, 1], ['X', -1, 0], ['E', 36, 1], ['C', 54, 1], ['B', 57, 4]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple feature engineering of the Titanic dataset\n",
    "import numpy as np\n",
    "cabin_data = np.array([\"C65\", \"\", \"E36\", \"C54\", \"B57 B59 B63 B66\"])\n",
    "def cabin_features(data):\n",
    "    features = []\n",
    "    for cabin in data:\n",
    "        cabins = cabin.split(\" \")\n",
    "        n_cabins = len(cabins)\n",
    "        # First char is the cabin_char\n",
    "        try:\n",
    "            cabin_char = cabins[0][0]\n",
    "        except IndexError:\n",
    "            cabin_char = \"X\"\n",
    "            n_cabins = 0\n",
    "        # The rest is the cabin number\n",
    "        try:\n",
    "            cabin_num = int(cabins[0][1:]) \n",
    "        except:\n",
    "            cabin_num = -1\n",
    "        # Add 3 features for each passanger\n",
    "        features.append( [cabin_char, cabin_num, n_cabins] )\n",
    "    return features\n",
    "\n",
    "cabin_features(cabin_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.95335821, -0.53358209, -0.9766791 ,  1.00559701, -0.99440299,\n",
       "        -0.62686567]), 0.046641791044776115)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature normalization\n",
    "num_data = np.array([1, 10, 0.5, 43, 0.12, 8])\n",
    "def normalize_feature(data, f_min=-1, f_max=1):\n",
    "    d_min, d_max = min(data), max(data)\n",
    "    factor = (f_max - f_min) / (d_max - d_min)\n",
    "    normalized = f_min + data*factor\n",
    "    return normalized, factor\n",
    "normalize_feature(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 0, 0, 1, 0, 1, 1]), array([1, 0, 1, 1, 0, 1, 0, 0])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting categorical data to numerical features\n",
    "cat_data = np.array(['male', 'female', 'male', 'male', 'female', 'male', 'female', 'female'])\n",
    "def cat_to_num(data):\n",
    "    categories = np.unique(data)\n",
    "    features = []\n",
    "    for cat in categories:\n",
    "        binary = (data == cat)\n",
    "        features.append(binary.astype(\"int\"))\n",
    "    return features\n",
    "\n",
    "cat_to_num(cat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 적용\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
